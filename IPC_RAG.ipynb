{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate , SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "#agents (I havent used it coz it was never needed)\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "#for langserve\n",
    "from fastapi import FastAPI\n",
    "import uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader instance\n",
    "loader = CSVLoader('ipc_sections.csv',encoding=\"utf-8\")\n",
    "\n",
    "#loading the documents from Csv file\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data \n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "chunks = splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " #embedding the data\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved into the vector database\n"
     ]
    }
   ],
   "source": [
    "#faiss db\n",
    "#Storing into Vector Data Base\n",
    "\n",
    "db_faiss = \"faiss_db\"\n",
    "db = FAISS.from_documents(chunks, embeddings)\n",
    "db.save_local(db_faiss)\n",
    "print(\"Saved into the vector database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a LLm \n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "   model_name=\"llama3-8b-8192\",\n",
    "   api_key= GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the ChatPromptTemplate\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"As a legal assistant specializing in criminal law in the Indian Penal Code (IPC), your task is to identify applicable legal sections relevant to the provided scenario. Below is the user's query. List all applicable legal sections for the scenario. If the provided context does not contain sufficient information to determine the relevant sections, respond with 'I'm unable to provide an answer based on the available information.'\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"Context: {context}\\n\\nQuery: {question}\"\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the stored vector DB\n",
    "db_faiss = \"faiss_db\"\n",
    "db = FAISS.load_local(db_faiss,\n",
    "                      embeddings,\n",
    "                      allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval QA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                       chain_type='stuff',\n",
    "                                       retriever=db.as_retriever(search_kwargs={'k': 30}),\n",
    "                                       return_source_documents=True,\n",
    "                                       verbose = True,\n",
    "                                       chain_type_kwargs={'prompt': chat_prompt_template}\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Answer: Based on the provided context and applicable legal sections, I have identified the following sections relevant to the scenario of married women:\n",
      "\n",
      "1. IPC 494 - Marrying again during the life-time of a husband or wife (punishment: 7 Years + Fine)\n",
      "2. IPC 498 - Enticing or taking away or detaining with a criminal intent a married woman (punishment: 2 Years and Fine)\n",
      "3. IPC 304B - Dowry death (punishment: Imprisonment for not less than 7 Years, but upto Life)\n",
      "4. IPC 376B - Sexual intercourse by husband upon his wife during separation (punishment: 2 to 7 years + Fine)\n",
      "5. IPC 498A - Punishment for subjecting a married woman to cruelty (punishment: 3 Years + Fine)\n",
      "6. IPC 376C - Sexual intercourse by a person in authority (punishment: Rigorous Imprisonment for 5 to 10 years + Fine)\n",
      "7. IPC 497 - Adultery (punishment: 5 Years or Fine or Both)\n",
      "8. IPC 493 - A man by deceit causing a woman not lawfully married to him to believe that she is lawfully married to him and to cohabit with him in that belief (punishment: 10 Years + Fine)\n",
      "\n",
      "Please note that some sections may be more relevant than others depending on the specific circumstances of the scenario.\n"
     ]
    }
   ],
   "source": [
    "# Query the model\n",
    "question = input(\"Enter your question: \")\n",
    "result = qa_chain({\"query\": question})\n",
    "\n",
    "# Extract and print the answer\n",
    "answer = result[\"result\"]\n",
    "print(\"\\nAnswer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legalrag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
